name: Upload Spark Application to GCS - STAGING
on:
  push:
    branches:
      - main
jobs:
  List-Buckets:
    permissions:
      contents: "read"
      id-token: "write"
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: "actions/checkout@v3"

      - id: "auth"
        name: "Authenticate to Google Cloud"
        uses: "google-github-actions/auth@v0"
        with:
          workload_identity_provider: 'projects/737712162241/locations/global/workloadIdentityPools/gh-pool/providers/gh-provider'
          service_account: 'terraform-gcp@sawyer-work-1804.iam.gserviceaccount.com'
          #token_format: 'access_token'
          access_token_lifetime: '300s'
          
      - name: "Set up Cloud SDK"
        uses: "google-github-actions/setup-gcloud@v0"
      
      - id: 'upload-folder'
        uses: 'google-github-actions/upload-cloud-storage@v0'
        with:
          path: ./scripts/spark-rdd-map.py
          destination: 'github_tf'
          export_default_credentials: true

      # - name: 'Delete files from bucket'
      #   run: |-
      #     gsutil rm gs://github_tf/**
        # Example of using the output
      # - id: 'uploaded-files'
      #   uses: 'foo/bar@main'
      #   env:
      #     files: '${{ steps.upload-folder.outputs.uploaded }}'